import matplotlib.pyplot as plt
import matplotlib.lines as lines
import matplotlib.dates as mdates
import _pickle as pickle
import numpy as np
import cv2
import json
import io
import os

from scipy.stats.kde import gaussian_kde
from scipy.stats import norm
import matplotlib.gridspec as grid_spec

import matplotlib.pyplot as plt
plt.rcParams["font.family"] = "Times New Roman"


"""
The basic idea is to create a grid of metric results, with each row corresponding to
a collection and each column corresponding to a metric readout. Each individual 
row,column combo will be generated by a function that takes in the metric set
and returns a figure. Then the overall figure can just plot these as a subplot
Perhaps one additional row should be added with an explanation (as text) of each plot
    PLOT 0 - Summary Spiderplot    
    PLOT 1 - MOT metrics as bar chart, with bar colored in red-green range, and label written on bar (horizontal)
    PLOT 2 - State Errors as ridgeline plot with axis in feet and other statistics shown
    PLOT 3 - Confusion Matrix
    PLOT 4 - Histogram of any of the metrics for which we record all values (vx, ax, theta, x_travelled, y_travelled)
    PLOT 5 - bar chart of any other unsupervised metrics 
"""

"""
There should also be a supplementary file with, for each metric, a description, and a best and worst value (for coloration)
"""

#%% Globals 
global results_dir
results_dir = "/home/derek/Documents/i24/trajectory-eval-toolkit/data/eval_results/"

global dpi
dpi = 162
global scale 
scale = 50
#plt.style.use("bmh")
global MD
MD = {
    "precision":{"text":"Precision","best":1,"bad":0.5},
    "recall":{"text":"Recall","best":1,"bad":0.5},
    "true_negative_rate":{"text":"TNR","best":1,"bad":0},
    "pred_match":{"text":"Pred Match Rate", "best":1,"bad":0.5},
    "gt_match":{"text":"GT Match Rate","best":1,"bad":0.5},
    "motp":{"text":"MOTP","best":1,"bad":0.5},
    "mota":{"text":"MOTA","best":1,"bad":0.5},
    "idr":{"text":"ID-Recall","best":1,"bad":0.5},
    "idp":{"text":"ID-Precision","best":1,"bad":0.5},
    "idf1":{"text":"ID-F1","best":1,"bad":0.5},
    "avg_ax_raw":{"text":"Acceleration"},
    "avg_vx_raw":{"text":"Speed"},
    "x_traveled_raw":{"text":"Trajectory Length","best":2000,"bad":300},
    "x_traveled_avg":{"text":"Trajectory Length","best":2000,"bad":300},
    "bps":{"text":"Hz","best":30,"bad":1},
    "traj_count":{"text":"Trajectories","best":np.nan},
    "x_variation":{"text":"X Variation","best":1,"bad":1.2},
    "y_variation":{"text":"Y Variation","best":0,"bad":50},
    "duration_avg":{"text": "Duration", "best":np.nan},
    "percent_backwards":{"text":"Backwards %","best":0,"bad":1},
    "overlaps_per_object":{"text":"Overlaps/Traj","best":0,"bad":1},
    "mostly_tracked%":{"text":">80% Tracked","best":1,"bad":0.2},
    "mostly_lost%":{"text":"<20% Tracked","best":0,"bad":0.4},
    "num_switches_per_gt":{"text":"Switches per GT","best":0,"bad":2},
    "num_fragmentations_per_gt":{"text":"Frag per GT","best":0,"bad":2},
    "pred_avg_matches":{"text":"GT IDs / Pred","best":1,"bad":2},
    "gt_avg_matches":{"text":"Pred IDs / GT","best":1,"bad":2},
    }

global color_pallette 
color_pallette = np.array([[117,158,186],   # for primary data
                           [160,120,120],   # for baseline / old data
                           [210,220,220],   # for other plots
                           [220,220,210],   # for other plots
                           [220,210,220],   # for other plots
                           [110,120,120],   # for other plots
                           [120,110,120],   # for other plots
                           [120,120,110],   # for other plots
                           [220,220,220],   # for cmap
                           [255,255,255]    # for pane default color
                           ])

color_pallette = np.array([[80,120,180],[150,100,100]])

global primary_colors
primary_colors = np.array([[117,158,186],
                           [117,158,176],
                           [117,140,186],
                           [110,158,186],
                           [117,168,186],
                           [117,158,176],
                           [117,140,186],
                           [110,158,186],
                           [117,168,186]])

global secondary_colors
secondary_colors = np.array([[160,120,120],
                             [160,129,120],
                             [180,120,120],
                             [166,116,120],
                             [148,120,110],
                             [160,125,100],
                             [170,122,120],
                             [166,116,120],
                             [148,120,120]])

# primary_colors = primary_colors[:,::-1]
# secondary_colors = secondary_colors[:,::-1]
# color_pallette = color_pallette[:,::-1]


global cmap
#cmap = lambda x: np.array([(255*(1-x),140,255*x)]).astype(np.uint8).tolist()
cmap = lambda x: color_pallette[0]*(x) + color_pallette[-2]*(1-x)

global classmap
classmap = ["sedan","midsize","van","pickup","semi","truck"]




#%% DONE

def f2a(fig):
    io_buf = io.BytesIO()
    fig.savefig(io_buf, format='raw')#, dpi=dpi)
    io_buf.seek(0)
    img_arr = np.reshape(np.frombuffer(io_buf.getvalue(), dtype=np.uint8),
                         newshape=(int(fig.bbox.bounds[3]), int(fig.bbox.bounds[2]), -1))
    io_buf.close()
    
    # RGB to BGR
    img_arr = img_arr.copy()
    temp = img_arr[:,:,0].copy()
    img_arr[:,:,0] = img_arr[:,:,2]
    img_arr[:,:,2] = temp
    return img_arr

def gen_title(results,figsize):
    name = results[0]["name"]
    iou = results[0]["iou_threshold"]
    comment = results[0]["description"]
    gt_dataset = results[0]["gt"]
    
    
    
    fig = plt.figure(figsize=(figsize[0]/scale,figsize[1]/scale))
    
    fig.text(0.01,0.8,"Collection: ",fontsize = 2500/scale)
    fig.text(0.25,0.8,"{}".format(name),fontsize = 2500/scale,color = color_pallette[0]/255)

    fig.text(0.01,0.3,"Notable changes:",fontsize = 1500/scale)
    fig.text(0.25,0.3,"{}".format(comment),fontsize = 1500/scale,wrap = True, va = "top")

    fig.text(0.01,0.45,"GT IOU:",fontsize = 1500/scale)
    fig.text(0.25,0.45,"{} ({})".format(iou,gt_dataset),fontsize = 1500/scale)

    if len(results) > 1:
        baseline_name = results[1]["name"]
        fig.text(0.01,0.6,"Baseline: ",fontsize = 1500/scale)
        fig.text(0.25,0.6,"{}".format(baseline_name),fontsize = 1500/scale,color = color_pallette[1]/255)

    return f2a(fig)

def unsup_title(results,figsize):
    fig = plt.figure(figsize=(figsize[0]/scale,figsize[1]/scale))
    fig.text(0.5,0.5,"Unsupervised Statistics",fontsize = 2500/scale, va = "center",ha = "center")
    return f2a(fig)

def sup_title(results,figsize):
    fig = plt.figure(figsize=(figsize[0]/scale,figsize[1]/scale))
    fig.text(0.5,0.5,"Supervised Metrics",fontsize = 2500/scale, va = "center",ha = "center")
    return f2a(fig)

def bar_MOT(results,figsize):
    """
    Ravel supervised MOT metrics into a bar_chart
    """
    
    include = ["idp","idr","recall","precision","mota","motp","gt_match", "pred_match"]#"true_negative_rate"]
    include = include[::-1]
    

    
    fig = plt.figure(figsize =(figsize[0]/scale,figsize[1]/scale))
    ax = fig.add_subplot(111)
    ax.spines.top.set_visible(False)
    ax.spines.left.set_visible(True)
    ax.spines.right.set_visible(False)
    ax.yaxis.set_ticks([])
    ax.tick_params(axis='x', labelsize= 1500/scale )  
    ax.set_xlim([0,1.1])
    #ax.set_position([0,0,1,1])
    
    both_val = []
    for ridx,result in enumerate(results):
        name = []
        val = []
        for met in include:
            if met in result:
                name.append(met)
                val.append(result[met])
    
        x_pos = np.arange(len(name))
        ax.barh(x_pos,val, align='center', color = color_pallette[ridx]/255, alpha=0.3)
        both_val.append(val)
        #ax.yticks(x_pos, name)
    
    for idx,lab in enumerate(name):
        # plot labels
        x_plot = val[idx]/3 if val[idx] > 0.4 else 0.5
        plot_lab = MD[lab]["text"]
        ax.text(x_plot,idx,plot_lab,fontsize = 1000/scale) 
        
        # plot values
        postval = both_val[0][idx]
        posttext = "{:.2f}".format(postval)
        x_plot = val[idx] + 0.01

        # plot old value if available
        if len(results) > 1:
            preval = both_val[1][idx]
            x_plot = max(both_val[0][idx],both_val[1][idx]) + 0.01

            pretext = "Old: {:.2f}".format(preval)
            ax.text(x_plot,idx+0.125,pretext,fontsize = 1000/scale,color = color_pallette[1]/255)

            diff = postval - preval
            sign = "" if diff < 0 else "+"
            posttext = "New: {:.2f} ({}{:.2f})".format(postval,sign,diff)        

        ax.text(x_plot,idx-0.125,posttext,fontsize = 1000/scale,color = color_pallette[0]/255)
        
       
    
    # Title
    fig.text(0.5,0.95,"MOT Metrics",fontsize = 2000/scale,ha = "center")
    return f2a(fig)

def conf_matrix(result,figsize):    
    n_c = len(classmap)
    confusion_matrix = result[0]["confusion_matrix"].data.numpy()[:n_c,:n_c] #* 1000 
    #plot confusion matrix
    sums = np.sum(confusion_matrix,axis= 0)
    sumss = sums[:,np.newaxis]
    sumss = np.repeat(sumss,confusion_matrix.shape[0],1)#.transpose()
    sumss = np.transpose(sumss)
    percentages = np.round(confusion_matrix/sumss * 100)
    
    fig = plt.figure(figsize =(figsize[0]/scale,figsize[1]/scale))
    ax = fig.add_subplot(111)
    
    colored = np.zeros([percentages.shape[0],percentages.shape[1],3])
    for i in range(colored.shape[0]):
        for j in range(colored.shape[1]):
            colored[i,j,:] = cmap(percentages[i,j]/100)
    
    colored /= 255
    
    im = ax.imshow(colored)#,cmap = "YlGn")
    
    classes =  classmap
    # We want to show all ticks...
    ax.set_xticks(np.arange(len(classes)))
    ax.set_yticks(np.arange(len(classes)))
    # ... and label them with the respective list entries
    ax.set_xticklabels(classes)
    ax.set_yticklabels(classes)
    ax.set_ylim(len(classes)-0.5, -0.5)
    # Rotate the tick labels and set their alignment.
    plt.setp(ax.get_xticklabels(), rotation=0, ha="center",
             rotation_mode="anchor",fontsize = 1400/scale)
    plt.setp(ax.get_yticklabels(), rotation=45, va="center",
         rotation_mode="anchor",fontsize = 1400/scale)
    
    # Loop over data dimensions and create text annotations.
    for i in range(len(classes)):
        for j in range(len(classes)):
            text = ax.text(j, i, "{}".format(int(confusion_matrix[i, j])),
                       ha="center", va="bottom", color="k",fontsize = 1000/scale)
            text = ax.text(j, i, str(percentages[i, j])+"%",
                       ha="center", va="top", color="k",fontsize = 1400/scale)
    
    ax.set_xlabel("Actual",fontsize = 1800/scale)
    ax.set_ylabel("Predicted",fontsize = 1800/scale)
    
    fig.text(0.5,0.95,"Class Confusion Matrix",fontsize = 2000/scale,ha = "center")

    
    return f2a(fig)
    
def death_pie(results,figsize):
    fig = plt.figure(figsize =(figsize[0]/scale,figsize[1]/scale))
    ax = fig.add_subplot(111)
    
    data = results[0]["cause_of_death"]
    
    labels = list(data.keys())
    vals = list(data.values())
    explode = ([0 for _ in range(len(labels))])  # only "explode" the 2nd slice (i.e. 'Hogs')
    colors = [color_pallette[i+2]/255 for i in range(len(labels))]
    
    # find "good" death type
    for lidx in range(len(labels)):
        if "FOV" in labels[lidx] or "fov" in labels[lidx]:
            good_idx = lidx
            break
    explode[good_idx] = 0.1
    colors[good_idx] = color_pallette[0]/255

    
    ax.pie(vals, explode=explode, labels=labels, autopct='%1.1f%%', colors = colors, textprops={'fontsize': 1400/scale},
            shadow=True, startangle=90, wedgeprops={"alpha":0.5})
    ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
    
    fig.text(0.5,0.95,"Object Cause of Death",fontsize = 2000/scale,ha = "center")
    #plt.tight_layout()


    return f2a(fig)

def state_error(results,figsize):
    state_names = ["X Position","Y Position", "Length", "Width", "Height"]
    
    fig = plt.figure(figsize =(figsize[0]/scale,figsize[1]/scale))
    # ax = fig.add_subplot(111)
    # ax.spines.top.set_visible(False)
    # ax.spines.left.set_visible(True)
    # ax.spines.right.set_visible(False)
    
    # get data
    data = results[0]["state_error"]
    xx = np.arange(-8,8,0.05)
    data = data.transpose(1,0)
    data_pdf = []
    for i in range(data.shape[0]):
        pdf = gaussian_kde(data[i])
        data_pdf.append(pdf(xx))
    data_pdf = np.stack(data_pdf)
    
    if len(results) > 1:
        data2 = results[1]["state_error"]
        data2 = data2.transpose(1,0)
        data2_pdf = []
        for i in range(data2.shape[0]):
            pdf = gaussian_kde(data2[i])
            data2_pdf.append(pdf(xx))
        data2_pdf = np.stack(data2_pdf)
        
    max_val = np.max(data_pdf)
    min_xval = min(xx)
    
    gs = (grid_spec.GridSpec(data.shape[0],1))
    
    #creating empty list
    ax_objs = []
    for didx in range(len(data_pdf)):
        # creating new axes object and appending to ax_objs
        ax_objs.append(fig.add_subplot(gs[didx:didx+1, 0:]))
    
        # plotting the distribution
        # filling the space beneath the distribution
        if len(results) > 1:
            ax_objs[-1].fill_between(xx,data2_pdf[didx],alpha = 1,color = color_pallette[1]/255)
        
        ax_objs[-1].fill_between(xx,data_pdf[didx],alpha = 0.5,color = color_pallette[0]/255)
        
        ax_objs[-1].plot(xx,data_pdf[didx],color = "black",linewidth = 2)
        ax_objs[-1].plot(xx,data2_pdf[didx],color = color_pallette[1]/255)


    
        # setting uniform x and y lims
        ax_objs[-1].set_xlim(min(xx),max(xx))
        ax_objs[-1].set_ylim(0,max_val)
    
        # make background transparent
        rect = ax_objs[-1].patch
        rect.set_alpha(0)
        
        # remove borders, axis ticks, and labels
        ax_objs[-1].set_yticklabels([])
        ax_objs[-1].set_yticks([])
        ax_objs[-1].set_ylabel('')
        
        if didx == data.shape[0]-1:
            ax_objs[-1].tick_params(axis='x', labelsize=1000/scale,length = 500/scale )
            ax_objs[-1].set_xlabel("Error Distribution (ft)", fontsize = 1500/scale)
        else:
            ax_objs[-1].set_xticklabels([])
            ax_objs[-1].tick_params(axis='x', length = 200/scale )

        
        spines = ["top","right","left"]#,"bottom"]
        for s in spines:
            ax_objs[-1].spines[s].set_visible(False)
        ax_objs[-1].text(min_xval,max_val/2,state_names[didx],fontweight="bold",fontsize = 1500/scale,va="bottom")
        
        ax_objs[-1].axvline(x = 0, ymax = 0.8, linestyle = ":",color = (0.2,0.2,0.2))
        
        
        # get mean,MAE, stddev, max
        mean = np.mean(data[didx])
        MAE  = np.mean(np.abs(data[didx]))
        stddev = np.std(data[didx])
        maxx = np.max(np.abs(data[didx]))
        
        ax_objs[-1].text(min_xval,max_val/2,                "Mean:  {:.1f}ft".format(mean),fontsize = 1000/scale,va="top")
        ax_objs[-1].text(min_xval,max_val/2-(0.05*max_val), "MAE:   {:.1f}ft".format(MAE),fontsize = 1000/scale,va="top")
        ax_objs[-1].text(min_xval,max_val/2-(0.1*max_val),  "Stdev: {:.1f}ft".format(stddev),fontsize = 1000/scale,va="top")
        ax_objs[-1].text(min_xval,max_val/2-(0.15*max_val), "Max:   {:.1f}ft".format(maxx),fontsize = 1000/scale,va="top")
        
        if len(results) > 1:
            
            mean = np.mean(data2[didx])
            MAE  = np.mean(np.abs(data2[didx]))
            stddev = np.std(data2[didx])
            maxx = np.max(np.abs(data2[didx]))
            
            xv = min_xval + 1.7
            ax_objs[-1].text(xv,max_val/2,               "({:.1f}ft)".format(mean),fontsize = 1000/scale,va="top", color= color_pallette[1]/255)
            ax_objs[-1].text(xv,max_val/2-(0.05*max_val),"({:.1f}ft)".format(MAE),fontsize = 1000/scale,va="top", color= color_pallette[1]/255)
            ax_objs[-1].text(xv,max_val/2-(0.1*max_val), "({:.1f}ft)".format(stddev),fontsize = 1000/scale,va="top", color= color_pallette[1]/255)
            ax_objs[-1].text(xv,max_val/2-(0.15*max_val),"({:.1f}ft)".format(maxx),fontsize = 1000/scale,va="top", color= color_pallette[1]/255)

    plt.tight_layout()
    gs.update(hspace= -0.2)
    
    
    fig.text(0.5,0.95,"State Error Histograms",fontsize = 2000/scale,ha = "center")
    return f2a(fig)
  
def unsup_hist(results,figsize):
    to_plot = ["x_traveled_raw","avg_vx_raw","avg_ax_raw"]
    units = ["ft","ft/s","ft/s$^2$"]
    xrange_clip = [[-500,2000],[-10,200],[-20,20]]
    
    fig = plt.figure(figsize =(figsize[0]/scale,figsize[1]/scale))
    # ax = fig.add_subplot(111)
    # ax.spines.top.set_visible(False)
    # ax.spines.left.set_visible(True)
    # ax.spines.right.set_visible(False)
    
    # get data
    data = [results[0][key] for key in to_plot]
    data = np.stack(data)
    #xx = np.arange(-8,8,0.05)
    data_pdf = []
    for i in range(data.shape[0]):
        pdf = gaussian_kde(data[i])
        xx = np.arange(np.min(data[i]),np.max(data[i]),1)
        data_pdf.append([xx,pdf(xx)])
    #data_pdf = np.stack(data_pdf)
    
    if len(results) > 1:
        data2 = [results[1][key] for key in to_plot]
        data2 = np.stack(data2)
        data2_pdf = []
        for i in range(data2.shape[0]):
            pdf = gaussian_kde(data2[i])
            xx = np.arange(np.min(data2[i]),np.max(data2[i]),1)
            data2_pdf.append([xx,pdf(xx)])
        #data2_pdf = np.stack(data2_pdf)
    
    gs = (grid_spec.GridSpec(1,len(data)))
    
    #creating empty list
    ax_objs = []
    for didx in range(len(data_pdf)):
        xx,dataD = data_pdf[didx]
        # creating new axes object and appending to ax_objs
        ax_objs.append(fig.add_subplot(gs[0:,didx:didx+1]))
        
        max_val = np.max(dataD)
        xr = [min(xx),max(xx)]

        # plotting the distribution
        # filling the space beneath the distribution
        if len(results) > 1:
            xx2,dataD2 = data2_pdf[didx]
            ax_objs[-1].fill_between(xx2,dataD2,alpha = 0.7,color = color_pallette[1]/255)
            ax_objs[-1].plot(xx2,dataD2,color = color_pallette[1]/255)
            
            max_val = max(np.max(dataD),np.max(dataD2))
            xr = [min(min(xx),min(xx2)),max(max(xx),max(xx2))]
            
        ax_objs[-1].fill_between(xx,dataD,alpha = 0.5,color = color_pallette[0]/255)
        ax_objs[-1].plot(xx,dataD,color = "black",linewidth = 2)


    
        # setting uniform x and y lims
        xr[0] = max(xr[0],xrange_clip[didx][0])
        xr[1] = min(xr[1],xrange_clip[didx][1])

        ax_objs[-1].set_xlim(xr[0],xr[1])
        ax_objs[-1].set_ylim(0,max_val)
    
        # make background transparent
        rect = ax_objs[-1].patch
        rect.set_alpha(0)
        
        # remove borders, axis ticks, and labels
        ax_objs[-1].set_yticklabels([])
        ax_objs[-1].set_yticks([])
        ax_objs[-1].set_ylabel('')
        
        if didx ==0:
            ax_objs[-1].set_ylabel('Frequency',fontsize = 2500/scale)
        
        #if didx == data.shape[0]-1:
        ax_objs[-1].tick_params(axis='x', labelsize=2000/scale,length = 500/scale )
        ax_objs[-1].set_xlabel("{}".format(units[didx]), fontsize = 2500/scale)
        # else:
        #     ax_objs[-1].set_xticklabels([])
        #     ax_objs[-1].tick_params(axis='x', length = 200/scale )

        text_height = 1
        
        spines = ["top","right","left"]#,"bottom"]
        for s in spines:
            ax_objs[-1].spines[s].set_visible(False)
        ax_objs[-1].text((xr[0]+xr[1])/2,max_val/text_height+(0.01*max_val),MD[to_plot[didx]]["text"],fontweight="bold",fontsize = 2500/scale,va="bottom",ha = "center")
        #ax_objs[-1].axvline(x = 0, ymax = 0.8, linestyle = ":",color = (0.2,0.2,0.2))
        
        if False:
            # get mean,MAE, stddev, max
            mean = np.mean(data[didx])
            MA  = np.mean(np.abs(data[didx]))
            stddev = np.std(data[didx])
            maxx = np.max(np.abs(data[didx]))
            
            xv = xr[0] #+  0.2*(xr[1] - xr[0])
            ax_objs[-1].text(xv,max_val/text_height,               "Mean:     {:.1f}{}".format(mean,units[didx]),fontsize = 1000/scale,va="top")
            ax_objs[-1].text(xv,max_val/text_height-(0.05*max_val),"Mean Abs: {:.1f}{}".format(MA,units[didx]),fontsize = 1000/scale,va="top")
            ax_objs[-1].text(xv,max_val/text_height-(0.1*max_val), "Stdev:    {:.1f}{}".format(stddev,units[didx]),fontsize = 1000/scale,va="top")
            ax_objs[-1].text(xv,max_val/text_height-(0.15*max_val),"Max:      {:.1f}{}".format(maxx,units[didx]),fontsize = 1000/scale,va="top")
            
            if len(results) > 1:
                mean = np.mean(data2[didx])
                MA  = np.mean(np.abs(data2[didx]))
                stddev = np.std(data2[didx])
                maxx = np.max(np.abs(data2[didx]))
                
                xv = xr[0] + 0.25*(xr[1] - xr[0])
                # may need a black border
                
                ax_objs[-1].text(xv,max_val/text_height,     " ({:.1f}{})".format(mean,units[didx]),fontsize = 1000/scale,va="top",ha="left", color=color_pallette[1]/255,bbox=dict(facecolor="white",edgecolor="white",alpha=0.7))
                ax_objs[-1].text(xv,max_val/text_height-(0.05*max_val)," ({:.1f}{})".format(MA,units[didx]),fontsize = 1000/scale,va="top",ha="left", color= color_pallette[1]/255,bbox=dict(facecolor="white",edgecolor="white",alpha=0.7))
                ax_objs[-1].text(xv,max_val/text_height-(0.1*max_val), " ({:.1f}{})".format(stddev,units[didx]),fontsize = 1000/scale,va="top",ha="left", color= color_pallette[1]/255,bbox=dict(facecolor="white",edgecolor="white",alpha=0.7))
                ax_objs[-1].text(xv,max_val/text_height-(0.15*max_val)," ({:.1f}{})".format(maxx,units[didx]),fontsize = 1000/scale,va="top",ha="left", color= color_pallette[1]/255,bbox=dict(facecolor="white",edgecolor="white",alpha=0.7))

    plt.tight_layout()
    #gs.update(hspace= -0.2)
    
    
    #fig.text(0.5,0.95,"Trajectory Attribute Histograms",fontsize = 2000/scale,ha = "center")
    #return f2a(fig)
    fig.savefig("hist.pdf", bbox_inches = "tight")

def chart_MOT(results,figsize):
    c_scale = 50000
    
    fig = plt.figure(figsize =(figsize[0]/scale,figsize[1]/scale))
    ax = fig.add_subplot(111)
    ax.set_position([0,0,1,1])
    ax.axis("off")

    # assemble list of metrics with ideal value (or -1 if none), new value, [old value]
    to_list = ["mostly_tracked%","mostly_lost%","num_switches_per_gt","num_fragmentations_per_gt","pred_avg_matches","gt_avg_matches"]
    coll_names = [result["name"] for result in results]
    cell_text = []
    
    
    data = np.zeros([len(to_list),len(coll_names)+1])
    
    print(results[0].keys())
    
    for qidx,quant in enumerate(to_list):
        row_text = []
        for ridx,result in enumerate(results):
            if quant in result.keys():
                data[qidx,ridx] = result[quant]
            else:
                data[qidx,ridx] = np.nan
        data[qidx,-1] = MD[quant]["best"]
    
    # normalize data by max data[:,0]
    data_norm = data / np.max(data[:,:2],axis = 1)[:,None]
    data_norm = data_norm.clip(0.001)
    
    w2h = figsize[0] / figsize[1]
    
    ns = len(to_list)
    nr = np.ceil(np.sqrt(ns/w2h)) 
    nc = np.ceil(  ns/nr)
    
    assert nc*nr >=ns, "Not enough cells for data"
    
    for idx in range(ns):
        for didx in range(len(results)-1,-1,-1):
            ax.scatter(idx//nr,idx%nr,s=data_norm[idx,didx]*c_scale,color = [color_pallette[didx]/255], alpha = 0.6)
        
        
        tshift = 0.2
        ax.text(idx//nr,idx%nr+tshift,MD[to_list[idx]]["text"],va="bottom",ha="center", fontsize = 1500/scale)
        txt = "{:.2f} ".format(data[idx,0])
        ax.text(idx//nr,idx%nr+tshift,txt,va="top",ha="right", fontsize = 1000/scale)
    
        if len(results) > 1:
            txt = " $\leftarrow$ ({:.2f})".format(data[idx,1])
            ax.text(idx//nr,idx%nr+tshift,txt,va="top",ha="left", fontsize = 1000/scale)
           
        best = data_norm[idx,2]
        if not np.isnan(best):
            # if best == 0:
            #     best += 0.0001
            ax.scatter(idx//nr,idx%nr,s=best*c_scale,facecolors='none', edgecolors=[0,0,0],linewidth = 2)
    
    ax.set_xlim([-0.5,nc-0.5])
    ax.set_ylim([-0.5,nr-0.3])
    
    return f2a(fig)

def chart_unsup(results,figsize):
    
    c_scale = 50000
    
    fig = plt.figure(figsize =(figsize[0]/scale,figsize[1]/scale))
    ax = fig.add_subplot(111)
    ax.set_position([0,0,1,1])
    ax.axis("off")

    # assemble list of metrics with ideal value (or -1 if none), new value, [old value]
    to_list = ["traj_count","bps","x_variation","y_variation","duration_avg","x_traveled_avg","percent_backwards","overlaps_per_object"]
    coll_names = [result["name"] for result in results]
    cell_text = []
    
    
    data = np.zeros([len(to_list),len(coll_names)+1])
    
    
    
    for qidx,quant in enumerate(to_list):
        row_text = []
        for ridx,result in enumerate(results):
            if quant in result.keys():
                data[qidx,ridx] = result[quant]
            else:
                data[qidx,ridx] = np.nan
        data[qidx,-1] = MD[quant]["best"]
    
    # normalize data by max data[:,0]
    data_norm = data / np.max(data[:,:2],axis = 1)[:,None]
    data_norm = data_norm.clip(0.001)
    
    w2h = figsize[0] / figsize[1]
    
    ns = len(to_list)
    nr = np.ceil(np.sqrt(ns/w2h)) 
    nc = np.ceil(  ns/nr)
    
    assert nc*nr >=ns, "Not enough cells for data"
    
    for idx in range(ns):
        for didx in range(len(results)-1,-1,-1):
            ax.scatter(idx//nr,idx%nr,s=data_norm[idx,didx]*c_scale,color = [color_pallette[didx]/255], alpha = 0.6)
        
        
        tshift = 0.2
        ax.text(idx//nr,idx%nr+tshift,MD[to_list[idx]]["text"],va="bottom",ha="center", fontsize = 1500/scale)
        txt = "{:.2f} ".format(data[idx,0])
        ax.text(idx//nr,idx%nr+tshift,txt,va="top",ha="right", fontsize = 1000/scale)
    
        if len(results) > 1:
            txt = " $\leftarrow$ ({:.2f})".format(data[idx,1])
            ax.text(idx//nr,idx%nr+tshift,txt,va="top",ha="left", fontsize = 1000/scale)
           
        best = data_norm[idx,2]
        if not np.isnan(best):
            # if best == 0:
            #     best += 0.0001
            ax.scatter(idx//nr,idx%nr,s=best*c_scale,facecolors='none', edgecolors=[0,0,0],linewidth = 2)
    
    ax.set_xlim([-0.5,nc-0.5])
    ax.set_ylim([-0.5,nr-0.3])
    
    return f2a(fig)

def history(results,figsize):
    """
    Collect all results within the given directory (same directory as results comes from)
    For each, determine whether calculated on same GT
    If so, get date (x_axis)
    Get aggregate score (y-axis)
    Get framerate (dot size)
    
    Scatter each (hollow if raw and solid if post-processed)
    Plot tie-lines from raw collectio to all post-processed collections
    
    Repeat plot of baseline and primary collections in correct colors
    """
    secondary_scale_power = 11            # adjust variation
    PSCALE = 0.003                        # adjust avg size

    primary_metric = "Total" # must be in spider
    secondary_metric = "Total" # adjusts size, must be in spider
    tertiary_metric = "mota" # adjusts transparency
    x_metric = "gen_time"
    
    names = []
    primaries = []
    secondaries = []
    tertiaries = []
    raw_names = []
    datetimes = []
    postprocessed = []
    
    for coll in os.listdir(results_dir):
        
        
        with open(os.path.join(results_dir,coll),"rb") as f:
            hist_result = pickle.load(f)
        hist_gt_coll = hist_result["gt"]
        if hist_gt_coll == results[0]["gt"]: # only keep results on same GT
            primaries.append(hist_result["spider"][primary_metric])
            secondaries.append(hist_result["spider"][secondary_metric])  
            tertiaries.append(hist_result[tertiary_metric])  
            names.append(coll.split(".")[0])
            raw_names.append(coll.split(".")[0].split("--")[0])
            datetimes.append(hist_result[x_metric])
            postprocessed.append(hist_result["postprocessed"])
    
    fig = plt.figure(figsize =(figsize[0]/scale,figsize[1]/scale))
    ax = fig.add_subplot(111)
    
    rn = max(primaries) - min(primaries)
    for idx in range(len(names)):
        x = datetimes[idx]
        y = primaries[idx]
        s = PSCALE * np.power(secondaries[idx],secondary_scale_power)
        color =  color_pallette[-2]/255
        fc= color #if postprocessed[idx] else "none"
        plt.scatter(x,y,s,facecolor = fc,alpha = tertiaries[idx])
        if not postprocessed[idx]:
            plt.scatter(x,y,s,linewidth = 2,edgecolor =  (.3,.3,.3),facecolor = fc)

        text_name = (names[idx].split("_")[-1] if postprocessed[idx] else raw_names[idx]) + " ({:.2f})".format(primaries[idx])
        plt.text(x,y+0*(rn),text_name,va = "center", ha = "center",fontsize = 600/scale,rotation = 0)
    
    # plot ties
    for i in range(len(names)):
        for j in range(len(names)):
            if postprocessed[i] and not postprocessed[j] and raw_names[i] == raw_names[j]: 
                x = [datetimes[i],datetimes[j]]
                y = [primaries[i],primaries[j]]
                plt.plot(x,y,linestyle = ":", color = (.3,.3,.3),linewidth = 1)
    
    if x_metric == "gen_time":
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))
        ax.xaxis.set_major_locator(mdates.DayLocator(interval=3))
    
    ax.spines["top"].set_visible(False)
    #ax.spines["left"].set_visible(False)
    ax.spines["right"].set_visible(False)

    #ax.set_ylabel("Aggregate Score",fontsize = 1500/scale)
    ax.set_xlabel(x_metric,fontsize = 1500/scale)
    ax.set_ylabel(primary_metric,fontsize = 1500/scale)

    #ax.set_yticklabels([])
    #ax.set_yticks([])
    ax.tick_params(axis='both', labelsize=1000/scale, length = 10,labelrotation = 45 )
    ax.set_ylim([min(primaries)-0.125,max(primaries)+0.125])
    
    
    # replot primary
    prim = results[0]["spider"][primary_metric]
    second = results[0]["spider"][secondary_metric]
    date = results[0][x_metric]
    post = results[0]["postprocessed"]
    s = PSCALE * np.power(second,secondary_scale_power)
    fc = color_pallette[0]/255 #if post else "none"
    lw =  4
    edge_color = color_pallette[0] / 255
    plt.scatter(date,prim,s,linewidth = lw,edgecolor =  edge_color,facecolor = fc)
    
    # replot  secondary
    if len(results) > 1:
        prim = results[1]["spider"][primary_metric]
        second = results[1]["spider"][secondary_metric]
        date = results[1][x_metric]
        post = results[1]["postprocessed"]
        s = PSCALE * np.power(second,secondary_scale_power)
        fc = color_pallette[1]/255 #if post else "none"
        lw =  4
        edge_color = color_pallette[1] / 255
        plt.scatter(date,prim,s,linewidth = lw,edgecolor =  edge_color,facecolor = fc)
    
    fig.subplots_adjust(bottom=0.25)
    
    # write out best results so far
    best_idx = np.argmax(np.array(primaries))
    best_coll= names[best_idx]
    best_text= "Current Best Result: {} ({:.1f})".format(best_coll,primaries[best_idx])
    fig.text(0.02,0.98,best_text, va = "top", fontsize = 1000/scale)
    
    primaries = [primaries[idx] * int(not postprocessed[idx]) for idx in range(len(primaries))]
    best_idx = np.argmax(np.array(primaries))
    best_coll= names[best_idx]
    best_text= "Current Best Raw Result: {} ({:.1f})".format(best_coll,primaries[best_idx])
    fig.text(0.02,0.94,best_text, va = "top", fontsize = 1000/scale)
    
    return f2a(fig)




def gen_spiderplot(results,figsize):
    fig = plt.figure(figsize =(figsize[0]/scale,figsize[1]/scale))
    ax = fig.add_subplot(111,projection="polar")
    ax.patch.set_facecolor((0.95,0.95,0.95))
    # Bars are sorted by the cumulative track length
    df_keys = list(results[0]["spider"].keys())
    total1 = results[0]["spider"]["Total"] 
    df_keys.remove("Total")
    
    df_sorted = [results[0]["spider"][key] + 0.01 for key in df_keys]
    
    if len(results) > 1:
        df2_sorted = [results[1]["spider"][key] + 0.01 for key in df_keys]
        total2 = results[1]["spider"]["Total"] 

    # Values for the x axis
    ANGLES = np.linspace(0.05, 2 * np.pi - 0.05, len(df_sorted), endpoint=False)
    
    # Cumulative length
    LENGTHS = df_sorted

    
    ax.set_theta_offset(0* np.pi / 2)
    ax.set_ylim(-0.2,1)
    
    # Add geometries to the plot -------------------------------------
    # See the zorder to manipulate which geometries are on top
    
    # Add bars to represent the cumulative track lengths
    if len(results) > 1:
        ax.bar(ANGLES+ 0.15*(2*np.pi/len(df_sorted)), df2_sorted, color=secondary_colors/255, alpha=0.6, width=0.52, zorder=10)
    ax.bar(ANGLES, LENGTHS, color=primary_colors/255, alpha=0.7, width=0.52, zorder=10)
    

    
    # Add dashed vertical lines. These are just for nicely dividing things
    ax.vlines(ANGLES+ 0.5*(2*np.pi/len(df_sorted)), 0, 1, color=[0,0,0], ls=(0, (4, 4)), zorder=11)
    
    # Add dots to represent the mean gain
    #ax.scatter(ANGLES, df_sorted, s=60, color=[0,0,0], zorder=11)
    
    # Remove unnecesary guides ---------------------------------------

    # Remove lines for polar axis (x)
    #ax.xaxis.grid(False)
    
    # Put grid lines for radial axis 
    ax.set_yticklabels([])
    y_ticks = [0.2,0.4,0.6,0.8,1]
    ax.set_yticks(y_ticks)
    
    # Add custom annotations -----------------------------------------
    # The following represent the heights in the values of the y axis
    # for tval in y_ticks:
    #     ax.text(np.pi / 2, tval, "{:.1f}".format(tval), ha="center", size=1000/scale)
    
    # Remove spines
    ax.spines["start"].set_color("none")
    ax.spines["polar"].set_color("none")
    
    
    # Adjust padding of the x axis labels ----------------------------
    # This is going to add extra space around the labels for the 
    # ticks of the x axis.
    XTICKS = ax.xaxis.get_major_ticks()
    for tick in XTICKS:
        tick.set_pad(20)

    # Set the labels
    ax.set_xticks(ANGLES)# + 0.5*(2*np.pi/len(df_sorted)))
    ax.set_xticklabels(df_keys, size=1500/scale)

    
    # annotate each score component
    for idx in range(len(df_keys)):
        ax.text(ANGLES[idx],0.5,"{:.2f}".format(df_sorted[idx]),size = 1500/scale,zorder = 100)

    fig.subplots_adjust(top=0.8)
    ly = 0.83
    fig.text(0.03,ly,"{:.1f}".format(total1),fontsize = 7000/scale, va = "bottom", ha = "left",color = color_pallette[0]/255)
    fig.text(0.03,ly," aggregate score",fontsize = 2000/scale, va = "top", ha = "left")

    if len(results) > 1:
        fig.text(0.97,ly,"{:.1f}".format(total2),fontsize = 7000/scale, va = "bottom", ha = "right",color = color_pallette[1]/255)
        fig.text(0.97,ly," baseline score",fontsize = 2000/scale, va = "top", ha = "right")

    fig.text(0.01,0.01,"Note: Each component is weighted to calculate aggregate score", va = "bottom", fontsize = 1000/scale)
    return f2a(fig)    

def gen_pane(results = [],
             size = [2160,3840],
             pane_layout = None,
             pane_functions = None,
             ):
    
    """
    Generates a dashboard layout with each of the specified panes filled by the 
    corresponding matplotlib plot function
    results - results dictionary generated by evaluate.py and loaded from pickle file
    pane_layout - iterable of item size 4 with grid x, grid y, width, height of each pane
    pane_functions - function used to create matplotlib (or other) figure to fill said pane (takes size as input)
    color_pallette - np.array.tolist() of size n,3
    color_spectrum - matplotlib colormap, for functions requiring spectrum - based color
    
    Importantly, the size for each plot is computed flexibly based on pane sizes and passed to the corresponding generation function,
    creating a tight layout - nice!
    """
    
    pad = 20
    shadow_pad = 18
    
    # TODO make pallette color [-1]
    dashboard = np.zeros([size[0],size[1],3]).astype(np.uint8) + 220
    
    # create placeholder panes
    pane_size = []
    pane_loc = []
    for pane in panes:
        color = color_pallette[-1].tolist()
        pane_coords = (int(pane[0]*size[0]/9 + pad),int(pane[1]*size[1]/16) + pad), (int((pane[0] + pane[2])*size[0]/9 - pad),int((pane[1] + pane[3])*size[1]/16 - pad))
        shadow_coords = (int(pane[0]*size[0]/9 + pad),int(pane[1]*size[1]/16) + pad), (int((pane[0] + pane[2])*size[0]/9 - shadow_pad),int((pane[1] + pane[3])*size[1]/16 - shadow_pad))

        pane_size.append([pane_coords[1][0] - pane_coords[0][0], pane_coords[1][1] - pane_coords[0][1]])
        pane_loc.append(pane_coords)
        
        dashboard = cv2.rectangle(dashboard,shadow_coords[0],shadow_coords[1],(190,190,190),-1)
        dashboard = cv2.rectangle(dashboard,pane_coords[0],pane_coords[1],color,-1)
    
    for idx,fn in enumerate(pane_functions):
        pane_coords = pane_loc[idx]
        pane_im = fn(results,pane_size[idx])
        if pane_im is not None:
            #pane_im = cv2.imload("temp.png")
            pane_im = cv2.resize(pane_im,pane_size[idx])
            dashboard[pane_coords[0][1]:pane_coords[1][1],pane_coords[0][0]:pane_coords[1][0],:] = pane_im[:,:,:3]
        
    
    
    # display image
    dashboard = cv2.resize(dashboard,(int(size[1]*0.95),int(size[0]*0.95)))
    cv2.imshow("frame",dashboard)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    
    cv2.imwrite("temp_dash.png",dashboard)
    
def dummy(a,b):
    pass




#%% TO BE IMPLEMENTED
    
if __name__ == "__main__":
    
    plt.figure()
    plt.plot([0,1],[0,1])
    plt.savefig("test.png")
    # load each result
    results = [
        #"/home/derek/Documents/i24/trajectory-eval-toolkit/data/eval_results/morose_panda--RAW_GT1_castigates.cpkl",
        #"/home/derek/Documents/i24/trajectory-eval-toolkit/data/eval_results/morose_panda--RAW_GT1.cpkl",
        #"/home/derek/Documents/i24/trajectory-eval-toolkit/data/eval_results/paradoxical_wallaby--RAW_GT1__boggles.cpkl",
        #"/home/derek/Documents/i24/trajectory-eval-toolkit/data/eval_results/paradoxical_wallaby--RAW_GT1.cpkl",
        # "/home/derek/Documents/i24/trajectory-eval-toolkit/data/eval_results/hollistic_anteater--RAW_GT1__administers.cpkl",
        # "/home/derek/Documents/i24/trajectory-eval-toolkit/data/eval_results/hollistic_anteater--RAW_GT1.cpkl",
        "/home/derek/Documents/i24/trajectory-eval-toolkit/data/eval_results/pristine_stork--RAW_GT1__negotiates.cpkl",
        "/home/derek/Documents/i24/trajectory-eval-toolkit/data/eval_results/pristine_stork--RAW_GT1.cpkl",
        ]

    for i in range(len(results)):
        with open(results[i],"rb") as f:
            results[i] = pickle.load(f)

    # pane = origin x, origin y, width , height
    panes = np.array([[0,0,4,1], # Title   # 
                      [0,1,4,3], # Spider
                      [0,4,4,3], # History
                      [0,7,4,2], # Death   #

                      [4,0.5,4,0.5], # Unsupervised Summary     #
                      [4,1,4,2], # Unsupervised General (List)
                      [4,3,4,6],  # Unsupervised Histograms     #
                      
                      [8,0.5,8,0.5], # Supervised Summary      #
                      [8,1,4,4], # MOT metrics (1-norm)        #
                      [8,5,4,4], # Confusion Matrix            #
 
                      [12,1,4,5], # State error                #  
                      [12,6,4,2], # MOT chart
                      [12,8,4,1], # Additional Hover Info
                      ])
    
    pane_functions = [gen_title,gen_spiderplot,history,death_pie,unsup_title,chart_unsup,unsup_hist,sup_title,bar_MOT,conf_matrix,state_error,chart_MOT,dummy]
    
    
    # gen_pane(results = results,
    #          pane_layout = panes,
    #          pane_functions= pane_functions,
    #          )
    
    
   